{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jigna\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\"https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\"\r\n",
    "\"https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html\"\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from wordcloud import WordCloud\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import gensim\r\n",
    "\r\n",
    "#Visualizations\r\n",
    "#import plotly.express as px\r\n",
    "#import seaborn as sns\r\n",
    "#import pyLDAvis.gensim\r\n",
    "#import chart_studio\r\n",
    "#import chart_studio.plotly as py \r\n",
    "#import chart_studio.tools as tls\r\n",
    "\r\n",
    "plt.style.use('seaborn')\r\n",
    "\r\n",
    "#data_path = \"data/santiago_covid_2020.csv\"\r\n",
    "#data_path = \"data/santiago_enero.csv\"\r\n",
    "data_path = \"data/gabrielboric.csv\"\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# spanish stop words\r\n",
    "stop_words = set(stopwords.words('spanish'))\r\n",
    "stop_words = ['t', 'si', 'q', 'https', 'co', 'solo', 'ser', 'bien', \r\n",
    "            'así', 'ma', 'mas', 'igual', 'va', 'después',\r\n",
    "            'hacer', 'hace', 'creo'] + list(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Métodos útiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hola', 'chao']\n"
     ]
    }
   ],
   "source": [
    "def delete_chars(text, unwanted_chars):\r\n",
    "    \"\"\"\r\n",
    "    useful method to replace a list of chars on text.\r\n",
    "    return:\r\n",
    "        (str) the same str without the chars in chars.\r\n",
    "    \"\"\"\r\n",
    "    for char in unwanted_chars:\r\n",
    "        text = text.replace(char, '')\r\n",
    "    return text\r\n",
    "\r\n",
    "def preprocess_tweet(tweet):\r\n",
    "    \"\"\"\r\n",
    "    Replaces unwanted characters and performs\r\n",
    "    a preprocessing.\r\n",
    "    input: \r\n",
    "        (str) tweet.\r\n",
    "    return:\r\n",
    "        (str[]) final: list of words.\r\n",
    "    \"\"\"\r\n",
    "    unwanted = ['#', ',', '.', '!', '?', '¿', '¡', '(',\\\r\n",
    "                ')', '-', '=', 'jaja', 'jajaja']\r\n",
    "    final = delete_chars(tweet, unwanted).split()\r\n",
    "    final = [w.lower() for w in final]\r\n",
    "    final = [w for w in final if w not in stop_words and len(w) > 3]\r\n",
    "    # Se eliminan links y @users\r\n",
    "    final = [w for w in final if w[:4] != 'http']\r\n",
    "    final = [w for w in final if w[:1] != '@']\r\n",
    "    return final\r\n",
    "    \r\n",
    "# mini mini test\r\n",
    "print(preprocess_tweet('##hola) ¿chao? =) jaja!'))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Sample:  Hoy nos reunimos con el Rector de la @uvalpochile @ocorralesj para conversar sobre educación superior y los desafíos de las universidades estatales para el nuevo Chile. Nuestro gobierno buscará fortalecer la #educación pública de calidad.  https://t.co/aXvXMWoNPx\n",
      "---------------------------------------------------------\n",
      "Cantidad de tweets:  39405\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_path)[['date', 'tweet']]\r\n",
    "print('---------------------------------------------------------')\r\n",
    "print('Sample: ', data.iloc[0]['tweet'])\r\n",
    "print('---------------------------------------------------------')\r\n",
    "print('Cantidad de tweets: ', len(data))\r\n",
    "print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reunimos',\n",
       " 'rector',\n",
       " 'conversar',\n",
       " 'educación',\n",
       " 'superior',\n",
       " 'desafíos',\n",
       " 'universidades',\n",
       " 'estatales',\n",
       " 'nuevo',\n",
       " 'chile',\n",
       " 'gobierno',\n",
       " 'buscará',\n",
       " 'fortalecer',\n",
       " 'educación',\n",
       " 'pública',\n",
       " 'calidad']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_tweet(data.iloc[0]['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25036    [mauro, consulta, cubrieron, inscripción, ayer...\n",
       "3527     [magallanes, región, aislada, geográficamente,...\n",
       "39198    [seminario, \"chile, bicentenario:, educación\",...\n",
       "24537    [grandes, empresarios, derecha, económica, pin...\n",
       "34873    [obvio, \"centro, plrural\", jeje, posibilidades...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se pre-procesan los tweets: Esto transforma cada\n",
    "# tweet en una colección de palabras.\n",
    "# processed_tweets corresponde a una lista de listas de palabras.\n",
    "\n",
    "processed_tweets = data['tweet'].map(preprocess_tweet)\n",
    "processed_tweets.head()\n",
    "\n",
    "# Se van a eliminar tweets pequeños: con menos de 5 palabras después\n",
    "# del preprocessing.\n",
    "dropers = []\n",
    "for ind, tweet in enumerate(processed_tweets):\n",
    "    if len(tweet) < 5:\n",
    "        dropers.append(ind) \n",
    "\n",
    "processed_tweets = processed_tweets.drop(dropers)\n",
    "processed_tweets.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 calidad\n",
      "1 chile\n",
      "2 conversar\n",
      "3 desafíos\n",
      "4 educación\n",
      "5 estatales\n",
      "Largo del diccionario:  1853\n"
     ]
    }
   ],
   "source": [
    "# Se crea el vocabulario. \r\n",
    "# Corresponde a crear una lista con todas las palabras involucrada \r\n",
    "# en el corpus asignando un índice único a cada una.\r\n",
    "\r\n",
    "dictionary = gensim.corpora.Dictionary(processed_tweets)\r\n",
    "\r\n",
    "# Se quitan palabras que aparecen en menos de 20 tweets y las\r\n",
    "# que aparecen en más del 50% del total de tweets (?).\r\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)\r\n",
    "\r\n",
    "c = 0\r\n",
    "for k, v in dictionary.iteritems():\r\n",
    "    print(k,v)\r\n",
    "    c += 1\r\n",
    "    if c > 5: break\r\n",
    "        \r\n",
    "print('Largo del diccionario: ', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet 0:  [(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]\n",
      "tweet 1:  [(14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Se transforman las palabras a vectores con el dictionary.\r\n",
    "# bow = \"bag of words\"\r\n",
    "\r\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_tweets]\r\n",
    "print('tweet 0: ', bow_corpus[0])\r\n",
    "print('tweet 1: ', bow_corpus[1])\r\n",
    "\r\n",
    "# Con esto cada tweet se representa como una colección de tuplas (w, a) \r\n",
    "# donde w es el índice de la palabra y a la cantidad de apariciones en ese\r\n",
    "# tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea y usa el lda model\r\n",
    "# Running LDA using Bag of Words\r\n",
    "\r\n",
    "# Train LDA model.\r\n",
    "from gensim.models import LdaModel\r\n",
    "\r\n",
    "# Set training parameters.\r\n",
    "num_topics = 5\r\n",
    "chunksize = 2000\r\n",
    "passes = 20\r\n",
    "iterations = 400\r\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\r\n",
    "\r\n",
    "# Make a index to word dictionary.\r\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\r\n",
    "id2word = dictionary#.id2token\r\n",
    "\r\n",
    "lda_model = LdaModel(\r\n",
    "    corpus=bow_corpus,\r\n",
    "    id2word=id2word,\r\n",
    "    chunksize=chunksize,\r\n",
    "    alpha='auto',\r\n",
    "    eta='auto',\r\n",
    "    iterations=iterations,\r\n",
    "    num_topics=num_topics,\r\n",
    "    passes=passes,\r\n",
    "    eval_every=eval_every\r\n",
    ")\r\n",
    "# LdaMulticore\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.019*\"gobierno\" + 0.017*\"izquierda\" + 0.011*\"movimiento\" + 0.011*\"estudiantil\" + 0.010*\"hecho\" + 0.010*\"parte\" + 0.010*\"dice\" + 0.009*\"años\" + 0.008*\"mejor\" + 0.008*\"nacional\"\n",
      "Topic: 1 \n",
      "Words: 0.065*\"ahora\" + 0.053*\"magallanes\" + 0.039*\"vamos\" + 0.030*\"arenas\" + 0.028*\"punta\" + 0.022*\"vivo\" + 0.020*\"reunión\" + 0.017*\"radio\" + 0.017*\"noalalzadelgas\" + 0.013*\"región\"\n",
      "Topic: 2 \n",
      "Words: 0.037*\"proyecto\" + 0.036*\"senado\" + 0.030*\"comisión\" + 0.024*\"reforma\" + 0.019*\"caso\" + 0.014*\"pueden\" + 0.013*\"feliz\" + 0.012*\"senuniv\" + 0.011*\"quiere\" + 0.011*\"asamblea\"\n",
      "Topic: 3 \n",
      "Words: 0.025*\"educación\" + 0.021*\"política\" + 0.015*\"acuerdo\" + 0.014*\"estudiantes\" + 0.012*\"derecha\" + 0.012*\"puede\" + 0.012*\"debate\" + 0.010*\"fuerza\" + 0.009*\"problema\" + 0.009*\"gente\"\n",
      "Topic: 4 \n",
      "Words: 0.041*\"chile\" + 0.024*\"abrazo\" + 0.022*\"gracias\" + 0.021*\"buena\" + 0.019*\"mañana\" + 0.019*\"fech\" + 0.017*\"recomiendo\" + 0.015*\"aquí\" + 0.015*\"universidad\" + 0.015*\"columna\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([(0.024766594, 'educación'),\n",
      "   (0.021487072, 'política'),\n",
      "   (0.015382866, 'acuerdo'),\n",
      "   (0.013553142, 'estudiantes'),\n",
      "   (0.01239962, 'derecha'),\n",
      "   (0.012371122, 'puede'),\n",
      "   (0.011599787, 'debate'),\n",
      "   (0.009595124, 'fuerza'),\n",
      "   (0.009045265, 'problema'),\n",
      "   (0.008895954, 'gente'),\n",
      "   (0.008856342, 'comparto'),\n",
      "   (0.008484627, 'tema'),\n",
      "   (0.008338762, 'debe'),\n",
      "   (0.008141142, 'trabajadores'),\n",
      "   (0.008140414, 'lucro'),\n",
      "   (0.008033856, 'ayer'),\n",
      "   (0.007570556, 'mismo'),\n",
      "   (0.007371407, 'derecho'),\n",
      "   (0.0071880505, 'cierto'),\n",
      "   (0.007187807, 'propuesta')],\n",
      "  -4.469048284996395),\n",
      " ([(0.040776458, 'chile'),\n",
      "   (0.024006506, 'abrazo'),\n",
      "   (0.022195345, 'gracias'),\n",
      "   (0.02106733, 'buena'),\n",
      "   (0.019345408, 'mañana'),\n",
      "   (0.019023027, 'fech'),\n",
      "   (0.017286511, 'recomiendo'),\n",
      "   (0.014723864, 'aquí'),\n",
      "   (0.014672941, 'universidad'),\n",
      "   (0.014622271, 'columna'),\n",
      "   (0.013414747, 'aguante'),\n",
      "   (0.0128342565, 'muchas'),\n",
      "   (0.012484553, 'seguir'),\n",
      "   (0.012404797, 'entrevista'),\n",
      "   (0.0123928115, 'gran'),\n",
      "   (0.012348957, 'apoyo'),\n",
      "   (0.011936494, 'saludos'),\n",
      "   (0.010722274, 'cabros'),\n",
      "   (0.010305432, 'universitario'),\n",
      "   (0.008496911, 'nuevo')],\n",
      "  -5.1556558593479505),\n",
      " ([(0.06483633, 'ahora'),\n",
      "   (0.05279271, 'magallanes'),\n",
      "   (0.039065786, 'vamos'),\n",
      "   (0.029673522, 'arenas'),\n",
      "   (0.028098775, 'punta'),\n",
      "   (0.022365848, 'vivo'),\n",
      "   (0.019805223, 'reunión'),\n",
      "   (0.017474761, 'radio'),\n",
      "   (0.016518729, 'noalalzadelgas'),\n",
      "   (0.012563951, 'región'),\n",
      "   (0.011656806, 'camino'),\n",
      "   (0.011069065, 'semana'),\n",
      "   (0.010088242, 'hablar'),\n",
      "   (0.009620293, 'conversar'),\n",
      "   (0.009615132, 'junto'),\n",
      "   (0.008832148, 'equipo'),\n",
      "   (0.008536679, 'saliendo'),\n",
      "   (0.008224312, 'campaña'),\n",
      "   (0.008053259, 'santiago'),\n",
      "   (0.0077729793, 'desarrollo')],\n",
      "  -5.841791705320164),\n",
      " ([(0.01911088, 'gobierno'),\n",
      "   (0.016947277, 'izquierda'),\n",
      "   (0.011385126, 'movimiento'),\n",
      "   (0.011083748, 'estudiantil'),\n",
      "   (0.010304669, 'hecho'),\n",
      "   (0.010047235, 'parte'),\n",
      "   (0.009548416, 'dice'),\n",
      "   (0.008964418, 'años'),\n",
      "   (0.008252825, 'mejor'),\n",
      "   (0.008204133, 'nacional'),\n",
      "   (0.008193446, 'compañeros'),\n",
      "   (0.008095885, 'menos'),\n",
      "   (0.0074517825, 'alguien'),\n",
      "   (0.0074369605, 'todas'),\n",
      "   (0.0071181105, 'piñera'),\n",
      "   (0.00667486, 'ministro'),\n",
      "   (0.0066419053, 'salud'),\n",
      "   (0.0065808063, 'autónoma'),\n",
      "   (0.006414879, 'debiera'),\n",
      "   (0.00632657, 'sido')],\n",
      "  -6.166169669209102),\n",
      " ([(0.036766525, 'proyecto'),\n",
      "   (0.036023658, 'senado'),\n",
      "   (0.03031179, 'comisión'),\n",
      "   (0.023573415, 'reforma'),\n",
      "   (0.019228075, 'caso'),\n",
      "   (0.014351842, 'pueden'),\n",
      "   (0.012714605, 'feliz'),\n",
      "   (0.011753105, 'senuniv'),\n",
      "   (0.011126146, 'quiere'),\n",
      "   (0.01099307, 'asamblea'),\n",
      "   (0.010670238, 'constitución'),\n",
      "   (0.010420546, 'terrible'),\n",
      "   (0.009900419, 'favor'),\n",
      "   (0.009683469, 'cámara'),\n",
      "   (0.009353247, 'jeje'),\n",
      "   (0.008991493, 'dijo'),\n",
      "   (0.008793707, 'voto'),\n",
      "   (0.008417692, 'porfa'),\n",
      "   (0.007900726, 'tributaria'),\n",
      "   (0.007880968, 'noche')],\n",
      "  -12.192677706381403)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\r\n",
    "\r\n",
    "top_topics = lda_model.top_topics(bow_corpus) #, num_words=20)\r\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar:\r\n",
    "\r\n",
    "#pyLDAvis.enable_notebook()\r\n",
    "#pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "#coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_tweets, dictionary=dictionary, coherence='c_v')\n",
    "#coherence_model_lda.get_coherence()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bea891d4f4659476d21e83a48ee1b355f8820be15a794f539b2195aa6b1473be"
  },
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}